etl {
  # Kafka configuration
  kafka {
    bootstrap-servers = "localhost:9092"
    bootstrap-servers = ${?KAFKA_BOOTSTRAP_SERVERS}
    
    input-topic = "news_raw"
    output-topic = "news_cleaned"
    
    consumer-group = "etl-spark-consumer"
    
    starting-offsets = "latest"
  }
  
  # Spark configuration
  spark {
    master = "local[*]"
    master = ${?SPARK_MASTER}
    
    app-name = "NewsPulse-ETL"
    
    checkpoint-location = "../data/checkpoints"
    checkpoint-location = ${?ETL_CHECKPOINT_LOCATION}
    
    # Trigger interval for structured streaming
    trigger-interval = "10 seconds"
  }
  
  # Delta Lake configuration
  delta {
    raw-path = "../data/lake/raw"
    raw-path = ${?DELTA_RAW_PATH}
    
    clean-path = "../data/lake/clean"
    clean-path = ${?DELTA_CLEAN_PATH}
  }
  
  # Text cleaning configuration
  cleaning {
    # Minimum content length (characters)
    min-content-length = 100
    
    # Maximum content length (characters)
    max-content-length = 50000
    
    # Remove articles with these patterns in title
    blocked-patterns = [
      "(?i)video:",
      "(?i)gallery:",
      "(?i)infographic:"
    ]
  }
  
  # Deduplication configuration
  dedup {
    # Window for deduplication (hours)
    window-hours = 24
    
    # Similarity threshold for near-duplicate detection
    similarity-threshold = 0.9
  }
}
